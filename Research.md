


Research Overview

- ## Advancing the Forward-Forward Algorithm

**Related fields**: Noise contrastive Learning, visual representations, un/self-supervised learning

**Introduction**: The Forward-Forward Algorithm, as conceptualized by Geoffrey Hinton, is a novel approach to learning in neural networks. This learning method is particularly distinctive because it replaces the traditional forward and backward passes of backpropagation—fundamental to deep learning— with two forward passes. This project can be presented as a step towards more energy-efficient and potentially biologically realistic forms of learning in artificial neural networks. 

To learn more about the details, I would recommend watching his interview, or my post for a general intro: 

- [Introduction Of The Forward Forward Method By Geoffrey Hilton](https://xing-chen18.github.io/Project-Introduction-of-the-forward-forward-method-by-Geoffrey-Hilton/)

**My Work**: I have developed an advanced method of generating negative data that diverges from and improves upon Geoffrey Hinton's initial Forward-Forward Algorithm framework. My approach has been tested on the CIFAR10 dataset, where it has not only achieved remarkable accuracy but also surpassed the performance benchmarks set by existing unsupervised local learning algorithms.

**Impact**: Improving machine learning models' interpretability. The implications extend to real-world applications, including but not limited to, enhanced computer vision systems, more efficient natural language processors, etc.

**Future work**: Scaling these methods for larger and more complex datasets and exploring the potential for broader applications in various AI domains.


- ## Neural Ordinary Differential Equations for modeling time series data

**Related fields**: Noise contrastive Learning, visual representations, un/self supervised learning

**Introduction**: Our research introduces a breakthrough method utilizing Neural Ordinary Differential Equations (Neural ODEs) to forecast the behavior of spintronic devices. Trained on minimal data, this dynamic neural network model offers high accuracy and remarkable time efficiency—an acceleration factor over 200 times—compared to traditional micromagnetic simulations.



## Reservoir computing for modeling time series data

Related field: Echo state network, Ridge regression


- [Project: What Is And Why Reservoir Computing](https://xing-chen18.github.io/Project-What-is-and-why-Reservoir-Computing/)

- [How does FFT helps in micromagnetic simulations](https://xing-chen18.github.io/My-PhD/)


## -Micromagnetic simulations for modeling magnetic materials

Related field: Echo state network, Ridge regression


- [Project: What Is And Why Reservoir Computing](https://xing-chen18.github.io/Project-What-is-and-why-Reservoir-Computing/)

- [How does FFT helps in micromagnetic simulations](https://xing-chen18.github.io/My-PhD/)


## -List of my posts
_I want to know more about other things_ 

- [Daily: Why Not Drink Hot Water From Tap](https://xing-chen18.github.io/Daily-Turning-Up-the-Heat-Why-You-Rethink-Drinking-Warm-Tap-Water/)

- [Know How: Git Usage](https://xing-chen18.github.io/know-how-Git-usage/)

- [Daily: How Does A Ticket Work](https://xing-chen18.github.io/Daily-How-does-a-ticket-work/)

- [Daily: Why Eu Countries Do Not Use Qr Code Payment As China Does](https://xing-chen18.github.io/Daily-Why-Eu-countries-do-not-use-QR-code-payment-as-China-does/)

- [Daily: Tunnel Vision](https://xing-chen18.github.io/Daily-Tunnel-vision/)

- [Daily: You Are Ready When You Are Ready](https://xing-chen18.github.io/Daily-You-are-ready-when-you-are-ready/)
