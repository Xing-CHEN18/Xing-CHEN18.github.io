---
published: true
---
Here's a nice video about interview of Geoffrey Hilton on his new Forwarad Forward algorithm, which I am currently working on based on his preliminary research. This interview is pretty cool as it shows us how a great idea was generated: thousands of times of trying, large amount of reading, consistent curiosity and explorations... and also hard working. "To have a great idea have a lot of them!" As Thomas Edison said. 

Video link: [https://www.youtube.com/watch?v=NWqy_b1OvwQ&t=1612s](https://www.youtube.com/watch?v=NWqy_b1OvwQ&t=1612s)

The first half of this video can be pretty technique, and pre-reading of his paper ([https://arxiv.org/abs/2212.13345](https://arxiv.org/abs/2212.13345)) is highly recommended to get better understanding of the talk.

<p align="center">
  <img alt="img-name" src="{{ site.baseurl }}/images/Hilton.png" height="auto" width="600">
    <em>Hilton is thinking, generated by DELLE 2, though not exactly the same as I want</em>
</p>

Here is a timeline about this video:

2.11: **why looking for something Beyond back propagation despite its tremendous success** 

Back propagation is a way of how much a change in the weight would make the system have less error and then you change the weight in proportion to how much it helps and obviously it hurts if you change it in the opposite direction. To calculate this weight change, it has to use the same connectivity pattern with the same weights but in the backwards direction and it has to go backwards through the non-linearity of the neuron. There's no evidence that the brain is doing that. **The worst case** is that if you're doing back propagation in a recurrent net, because you need tp run the recurrent net forwards in time and then you have to run it backwards through time in order to get all these derivatives so as to change the weights. That's particularly problematic if for example if you're trying to process video because you can't stop and go backwards in time. So combined with the fact that there's no good evidence the brain does it, and there's the problem that for technology it's a mess it interrupts the pipelining of stuff through. So you'd really like something like video there's been multiple stages of processing and you'd like to just pipeline the inputs through those multiple stages and just keep pipelining it through.


5.16: **Explanation of the forward forward algorithm** 

The idea of the forward forward algorithm is that if you can divide the learning process of getting the
gradients you need into two separate phases, you can do one of them online and one of them offline. The way you do online can be very simple and will allow you to just pipeline stuff through so the online phase which is meant to correspond to wake where you put input into the network. let's take the recurrent version as an example: input keeps coming into the network and what you're trying to do for each layer at each time step is you're trying to make the layer of high activity or rather high enough activity so that it can figure out that this is real data so the underlying idea is, for Real data you want every layer to have high activity and for fake data what comes out we get that later you'd like every layer to have low activity, and the task of the network or the thing it's trying to achieve is not to give the correct label (as in back propagation is trying to achieve this property) but being able to tell the difference between real data and fake data at every layer by each layer having high activity for real data and no activity for fake data so each layer has its own objective function. 


In fact, & to be more precise we take the sum of the squares of the activities of the units in a layer, we subtract off some thresholds and then we feed that to a logistic function that simply decides what's the probability that this is a real data as opposed to fake data and if the logistical function gets a lot of input it will say it's definitely real data and so there's no need to change anything, if it's getting lots of input you won't learn on that example because it's already getting it right and that explains how you can run lots of positive examples without running any negative examples which are fake data because it'll just saturate on positive examples it's getting right. So that's what it does in the positive phase where it tries to get high sum of squared activities in every layer so that it can tell that it's real data, and in the negative phase which is run Offline (that is during sleep) the network needs to generate its own data and try to give its own data as input, where it wants to have low activity in every layer. So the network has to learn a generative model and what it's trying to do is to discriminate between real data and fake data produced by its generative model. Obviously if it can't discriminate at all then what's going to happen is the derivatives that it gets for real data and the derivatives we get for fake data will be equal and opposite so it won't learn anything, and learning will have finished. Then if you can't tell the difference between what it generates and real data, this is very like again if you know about generative adversarial Networks (GAN) except that the discriminative net that's trying to tell the difference between real and fake and the generative model that's trying to generate fake
data use the same hidden units and so they use the same hidden representations that overcomes a lot of the problems that a GAN has. On the other hand because it's not doing back propagation to learn the generative
model it's harder to learn a good General model. That's a rough overview of the algorithm.

9.13: **Cyclying between wake/sleep or?** 

Most of the research what I would do is the preliminary research. Cyclying quickly between them because that's the obvious thing to do and later on I discovered well I've known for some time that with contrastive learning you can separate the phases and later on I discovered it worked pretty well to separate the phases.
Recent experiments I've done with predicting characters. You can have it predict about a quarter of a million characters when it's running on real data and trying to predict the next character is making predictions. And it's running with mini batches, so after making quite a large number of predictions they're going to updates the weights and then it sees more positive examples it updates weights again, so in all those phases it's just trying to get higher activity in the hidden layers but only if it's not already got high activity, and you can predict like quarter of a million characters in the positive phase and then switch to the negative phase where the Network's generating its own string of characters and you're now trying to get low activity in the hidden layers for the characters it's predicting. It's looking at a little window characters and then you run for quarter of a million characters like that and it doesn't actually have to be the same number anymore.  In Boltzman machines it's very important to have the same number of things in the positive phase and negative phase but with this it isn't. The most remarkable is that up to a few hundred thousand predictions it works almost as well if you separate the phases as opposed to interleave and that's quite surprising.

11.08: **How this wate/sleep phase relate to human learning** 

In human learning, we can sleep for complicated Concepts that you're learning but there's learning going on all the time that doesn't require a sleep phase well. There is in this too, if you're just running on positive examples it's changing the weights for all the examples where it's not completely obvious that this is a positive data so it does a lot of learning in the positive phase but if you go on too long you fails catastrophically and people seem to be the same if probably sleep for a week you'll go completely psychotic and you may never recover.


12.17: **How to understand the negative data** 

What I mean by negative data is data that you give to the system when it's running in the negative phase
that is when it's trying to get low activity in all the hidden layers and there are many ways of generating
negative data in the end you'd like the model itself to generate the negative data. So this is just like it was in Boltzman machines the data that the model itself generates is negative data and real data is what
you're trying to model and once you've got a really good model, the negative data looks just like the real data so no lo longer takes place. But negative data doesn't have to be produced by the model. For example you can train it to do supervised learning by inputting both an image and the label, so now the label's part of the input not part of the output and what you're asking it to do is when I input an image with the correct label that's going to be the positive data you want to have high activity. You want to input an image with the incorrect label which I just put in by hand that's the incorrect as an incorrect label that's negative data now. It works best if you get the model to predict the label and you put in the best of the model's predictions it's not correct because then you're giving it the things it's most the mistake is most likely to make as negative data but you can put in negative data by hand and it works fine.


18.04: **How to understand the negative data** 

right wish that there's no no good
evidence of
derivative information thrown back the
studies these error gradients flowing
backwards okay obviously the brain has
top down connections if you look at the
perceptual system there's a kind of
forward direction that goes from
the thalamus up to him for a temporal
cortex where you recognize things and
the thalamus is a sort of where the
input comes in from the eyes
and there's Connections in the backward
Direction but the connection in the
backward Direction don't look at all
like what you'd need for back
propagation for example in two cortical
areas the connection is coming back
don't go to the same cells as
connections going forward come from
it's not reciprocal in that sense yeah
there's a loop between the cortical
areas but information in one course got
area goes through about six different
neurons before it gets back to where it
started
and so it's a loop it's not uh it's not
like a mirrored system
okay but my question is you talk about
turning the static image into a boring
video that allows you to have top-down
effects that's right yeah so you have to
think of the being a forward Direction
which is going from lower layers to
higher layers
and then orthogonal to that was the time
dimension
and so if I have a video even if it's a
video of just a single thing that stays
still
I can be going up and down through the
layers as I go forwards in time
and that's what's allowing you to have
top down effects
okay I understood that yeah each layer
can receive inputs from a higher layer
in the previous time step exactly yeah
so what a layer is doing it's receiving
input from higher layers
and lower layers at the previous time
step and from itself at the previous
time step
and if you've got static input
that whole process over time looks like
a network settling down
that's a bit more like a Baltimore
machine settling down
and the idea is that
the time that you're using for that is
the same as the time you're using for
posting video
and because of that
if I give you fast input that's changing
too fast you can never settle down to
interpret it
so I discovered this nice phenomenon if
you take a new regularly shaped object
like a potato for example a nice
irregularly shaped potato
and you throw it up in the air rotating
slowly at one or two revolutions per
second
you cannot see what shape it is you just
can't see the shape of it
you don't have time to settle on a 3D
interpretation
because it's the very same
time steps that you're using for posting
videos you're using for settling with a
static image
and what I found fascinating about and
maybe this is something that that is
already
in the literature but this idea of going
up and down in the layers
As you move through time
but it's that's always been in recurrent
Nets so to begin with recurrentness we
just have one hidden layer so typical
lstms and so on would have one hidden
there and then Alex Graves
the idea of having multiple hidden
layers and showed that it was a winner
so that idea has been around but it's
always been paired with back propagation
as the learning algorithm and in that
case it was back propagation through
time which was completely unrealistic
but



























