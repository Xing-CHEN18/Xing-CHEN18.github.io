---
published: true
---
Here's a nice video about interview of Geoffrey Hilton on his new Forwarad Forward algorithm, which I am currently working on based on his preliminary research. This interview is pretty cool as it shows us how a great idea was generated: thousands of times of trying, large amount of reading, consistent curiosity and explorations... and also hard working. "To have a great idea have a lot of them!" As Thomas Edison said. 

Video link: [https://www.youtube.com/watch?v=NWqy_b1OvwQ&t=1612s](https://www.youtube.com/watch?v=NWqy_b1OvwQ&t=1612s)

The first half of this video can be pretty technique, and pre-reading of his paper ([https://arxiv.org/abs/2212.13345](https://arxiv.org/abs/2212.13345)) is highly recommended to get better understanding of the talk.

<p align="center">
  <img alt="img-name" src="{{ site.baseurl }}/images/Hilton.png" height="auto" width="600">
    <em>Hilton is thinking, generated by DELLE 2, though not exactly the same as I want</em>
</p>

Here is a timeline about this video:

2.11: **why looking for something Beyond back propagation despite its tremendous success** 

Back propagation is a way of how much a change in the weight would make the system have less error and then you change the weight in proportion to how much it helps and obviously it hurts if you change it in the opposite direction. To calculate this weight change, it has to use the same connectivity pattern with the same weights but in the backwards direction and it has to go backwards through the non-linearity of the neuron. There's no evidence that the brain is doing that. **The worst case** is that if you're doing back propagation in a recurrent net, because you need tp run the recurrent net forwards in time and then you have to run it backwards through time in order to get all these derivatives so as to change the weights. That's particularly problematic if for example if you're trying to process video because you can't stop and go backwards in time. So combined with the fact that there's no good evidence the brain does it, and there's the problem that for technology it's a mess it interrupts the pipelining of stuff through. So you'd really like something like video there's been multiple stages of processing and you'd like to just pipeline the inputs through those multiple stages and just keep pipelining it through.

5.16: **Explanation of the forward forward algorithm** 

The idea of the forward forward algorithm is that if you can divide the learning the process of getting the
gradients you need into two separate phases you can do one of them online and one of them offline. The way you do online can be very simple and will allow you to just pipeline stuff through so the online phase which is meant to correspond to wake, you put input into the network and let's take the recurrent version
input keeps coming into the network
and what you're trying to do
for each layer at each time step
you're trying to make
the layer of high activity
or rather high enough activity so that
it can
figure out that this is real data
so the underlying idea is for Real data
you want every layer to have high
activity and for fake data what comes
out we get that later you'd like every
layer to have low activity
and the task of the network or the thing
it's trying to achieve
is not to give the correct label as in
back propagation is trying to achieve
this property but being able to tell the
difference between real data and fake
data at every layer by each layer having
high activity for real data and no
activity for fake data
so each layer has its own objective
function
in fact to be more precise we take the
sum of the squares of the activities of
the units in a layer
we subtract off some thresholds
and then we feed that to a logistic
function that simply decides what's the
probability that this is a is real data
as opposed to fake data
and if the logistical function gets a
lot of input it will say it's definitely
real data
and so there's no need to change
anything if it's getting lots of input
you won't learn on that example because
it's already getting it right
and that explains how you can run lots
of positive examples without running any
negative examples which are fake data
because it'll just saturate on positive
examples it's getting right
so that's what it does in the positive
phase it tries to get high sum of
squared activities in every layer so
that it can tell high enough so it can
tell that it's real data
in the negative phase
which is run Offline that is during
sleep
the network needs to generate its own
data
and try and get given its own data as
input
it wants to have low activity in every
layer
so the network has to learn a generative
model
and what it's trying to do is
discriminate between real data and fake
data produced by its generative model
obviously if it can't discriminate at
all
then what's going to happen is the
derivatives that it gets for real data
and the derivatives we get for fake data
will be equal and opposite so it won't
learn anything learning will have
finished then if you can't tell the
difference between what it generates and
real data
this is very like again if you know
about generative adversarial Networks
except that the discriminative net
that's trying to tell the difference
between real and fake and the generative
model that's trying to generate fake
data use the same hidden units and so
they use the same hidden representations
that overcomes a lot of the problems
that a gun has
on the other hand because it's not doing
back propagation to learn the generative
model it's harder to learn a good
General model
that's a rough overview of the algorithm

9.13: **Cyclying between wake/sleep or?** 

okay so most of the research what I
would do is
the preliminary research cycle quickly
between them because that's the obvious
thing to do
and later on I discovered
well I've known for some time that with
contraceptive learning you can separate
the phases
and later on I discovered it worked
pretty well to separate the phases
recent experiments I've done with
predicting characters
You can predict
you can have it predict about a quarter
of a million characters so it's running
on real data trying to predict the next
character is making predictions he's
running with mini batches so after
making quite a large number of
predictions they're going to updates the
weights and then it sees more positive
examples it updates away scan so in all
those phases it's just trying to get
higher activity
in the hidden layers
but only if it's not already got high
activity
and you can predict like quarter of a
million characters in the positive phase
and then switch to the negative phase
where the Network's generating its own
string of characters
and
it you're now trying to get
low activity in the hidden layers for
the characters it's predicting
it's looking a little window characters
and then you run for quarter of a
million characters like that and it
doesn't actually have to be the same
number anymore we've bought some
machines it's very important to have the
same number of things in the positive
phase and negative phase but with this
it isn't
the most remarkable is
that up to a few hundred thousand
predictions
it works almost as well if you separate
the phases
as opposed to interleave
and that's quite surprising.


in human learning
certainly in the we can sleep for
complicated Concepts that you're
learning but there's learning going on
all the time that
doesn't require a sleep phase well there
is in this too if you're just running on
positive examples
it's changing the weights
for all the examples where it's not
completely obvious that this is a
positive data
so it will do a lot of it does a lot of
learning in the positive phase
but if you go on too long you fails
catastrophically
and people seem to be the same if I
probably sleep for a week you'll go
completely psychotic
and job hallucinations and you may never
recover


