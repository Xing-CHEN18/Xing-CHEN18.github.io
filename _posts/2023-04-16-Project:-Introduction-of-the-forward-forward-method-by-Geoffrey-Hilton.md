---
published: true
---
Here's a nice video about interview of Geoffrey Hilton on his new Forwarad Forward algorithm, which I am currently working on based on his preliminary research. This interview is pretty cool as it shows us how a great idea was generated: thousands of times of trying, large amount of reading, consistent curiosity and explorations... and also hard working. "To have a great idea have a lot of them!" As Thomas Edison said. 

Video link: [https://www.youtube.com/watch?v=NWqy_b1OvwQ&t=1612s](https://www.youtube.com/watch?v=NWqy_b1OvwQ&t=1612s)

The first half of this video can be pretty technique, and pre-reading of his paper ([https://arxiv.org/abs/2212.13345](https://arxiv.org/abs/2212.13345)) is highly recommended to get better understanding of the talk.

<p align="center">
  <img alt="img-name" src="{{ site.baseurl }}/images/Hilton.png" height="auto" width="600">
    <em>Hilton is thinking, generated by DELLE 2, though not exactly the same as I want</em>
</p>

Here is a timeline about this video:

2.11: **why looking for something Beyond back propagation despite its tremendous success** 

Back propagation is a way of how much a change in the weight would make the system have less error and then you change the weight in proportion to how much it helps and obviously it hurts if you change it in the opposite direction. To calculate this weight change, it has to use the same connectivity pattern with the same weights but in the backwards direction and it has to go backwards through the non-linearity of the neuron. There's no evidence that the brain is doing that. **The worst case** is that if you're doing back propagation in a recurrent net, because you need tp run the recurrent net forwards in time and then you have to run it backwards through time in order to get all these derivatives so as to change the weights. That's particularly problematic if for example if you're trying to process video because you can't stop and go backwards in time. So combined with the fact that there's no good evidence the brain does it, and there's the problem that for technology it's a mess it interrupts the pipelining of stuff through. So you'd really like something like video there's been multiple stages of processing and you'd like to just pipeline the inputs through those multiple stages and just keep pipelining it through.


5.16: **Explanation of the forward forward algorithm** 

The idea of the forward forward algorithm is that if you can divide the learning process of getting the
gradients you need into two separate phases, you can do one of them online and one of them offline. The way you do online can be very simple and will allow you to just pipeline stuff through so the online phase which is meant to correspond to wake where you put input into the network. let's take the recurrent version as an example: input keeps coming into the network and what you're trying to do for each layer at each time step is you're trying to make the layer of high activity or rather high enough activity so that it can figure out that this is real data so the underlying idea is, for Real data you want every layer to have high activity and for fake data what comes out we get that later you'd like every layer to have low activity, and the task of the network or the thing it's trying to achieve is not to give the correct label (as in back propagation is trying to achieve this property) but being able to tell the difference between real data and fake data at every layer by each layer having high activity for real data and no activity for fake data so each layer has its own objective function. 


In fact, & to be more precise we take the sum of the squares of the activities of the units in a layer, we subtract off some thresholds and then we feed that to a logistic function that simply decides what's the probability that this is a real data as opposed to fake data and if the logistical function gets a lot of input it will say it's definitely real data and so there's no need to change anything, if it's getting lots of input you won't learn on that example because it's already getting it right and that explains how you can run lots of positive examples without running any negative examples which are fake data because it'll just saturate on positive examples it's getting right. So that's what it does in the positive phase where it tries to get high sum of squared activities in every layer so that it can tell that it's real data, and in the negative phase which is run Offline (that is during sleep) the network needs to generate its own data and try to give its own data as input, where it wants to have low activity in every layer. So the network has to learn a generative model and what it's trying to do is to discriminate between real data and fake data produced by its generative model. Obviously if it can't discriminate at all then what's going to happen is the derivatives that it gets for real data and the derivatives we get for fake data will be equal and opposite so it won't learn anything, and learning will have finished. Then if you can't tell the difference between what it generates and real data, this is very like again if you know about generative adversarial Networks (GAN) except that the discriminative net that's trying to tell the difference between real and fake and the generative model that's trying to generate fake
data use the same hidden units and so they use the same hidden representations that overcomes a lot of the problems that a GAN has. On the other hand because it's not doing back propagation to learn the generative
model it's harder to learn a good General model. That's a rough overview of the algorithm.

9.13: **Cyclying between wake/sleep or?** 

Most of the research what I would do is the preliminary research. Cyclying quickly between them because that's the obvious thing to do and later on I discovered well I've known for some time that with contrastive learning you can separate the phases and later on I discovered it worked pretty well to separate the phases.
Recent experiments I've done with predicting characters. You can have it predict about a quarter of a million characters when it's running on real data and trying to predict the next character is making predictions. And it's running with mini batches, so after making quite a large number of predictions they're going to updates the weights and then it sees more positive examples it updates weights again, so in all those phases it's just trying to get higher activity in the hidden layers but only if it's not already got high activity, and you can predict like quarter of a million characters in the positive phase and then switch to the negative phase where the Network's generating its own string of characters and you're now trying to get low activity in the hidden layers for the characters it's predicting. It's looking at a little window characters and then you run for quarter of a million characters like that and it doesn't actually have to be the same number anymore.  In Boltzman machines it's very important to have the same number of things in the positive phase and negative phase but with this it isn't. The most remarkable is that up to a few hundred thousand predictions it works almost as well if you separate the phases as opposed to interleave and that's quite surprising.

11.08: **How this wate/sleep phase relate to human learning** 

In human learning, we can sleep for complicated Concepts that you're learning but there's learning going on all the time that doesn't require a sleep phase well. There is in this too, if you're just running on positive examples it's changing the weights for all the examples where it's not completely obvious that this is a positive data so it does a lot of learning in the positive phase but if you go on too long you fails catastrophically and people seem to be the same if probably sleep for a week you'll go completely psychotic and you may never recover.


12.17: **How to understand the negative data** 

What I mean by negative data is data that you give to the system when it's running in the negative phase
that is when it's trying to get low activity in all the hidden layers and there are many ways of generating
negative data in the end you'd like the model itself to generate the negative data. So this is just like it was in Boltzman machines the data that the model itself generates is negative data and real data is what
you're trying to model and once you've got a really good model, the negative data looks just like the real data so no lo longer takes place. But negative data doesn't have to be produced by the model. For example you can train it to do supervised learning by inputting both an image and the label, so now the label's part of the input not part of the output and what you're asking it to do is when I input an image with the correct label that's going to be the positive data you want to have high activity. You want to input an image with the incorrect label which I just put in by hand that's the incorrect as an incorrect label that's negative data now. It works best if you get the model to predict the label and you put in the best of the model's predictions it's not correct because then you're giving it the things it's most the mistake is most likely to make as negative data but you can put in negative data by hand and it works fine.


18.04: **Why Turning a static image into a boring video allows to have top-down effects** 

(there's no no good evidence of derivative information thrown back. Obviously the brain has top down connections if you look at the perceptual system there's a kind of forward direction that goes from the thalamus up to him for a temporal cortex where you recognize things and the thalamus is a sort of where the input comes in from the eyes and there's Connections in the backward Direction but the connection in the backward Direction don't look at all like what you'd need for back propagation for example in two cortical areas the connection is coming back don't go to the same cells as connections going forward come from it's not reciprocal in that sense. There's a loop between the cortical areas but information in one course got area goes through about six different neurons before it gets back to where it started and so it's a loop it's not and it's not like a mirrored system) 

So you have to think of the being a forward Direction which is going from lower layers to higher layers
and then orthogonal to that was the time dimension and so if I have a video even if it's a video of just a single thing that stays still, I can be going up and down through the layers as I go forwards in time
and that's what's allowing you to have top down effects. So what a layer is doing it's receiving
input from higher layers and lower layers at the previous time step and from itself at the previous
time step and if you've got static input that whole process over time looks like a network settling down.
That's a bit more like a Boltzman machine settling down and the idea is that the time that you're using for that is the same as the time you're using for posting video and because of that if I give you fast input that's changing too fast you can never settle down to interpret it. So I discovered this nice phenomenon if
you take a new regularly shaped object like a potato for example a nice irregularly shaped potato and you throw it up in the air rotating slowly at one or two revolutions per second you cannot see what shape it is you just can't see the shape of it, you don't have time to settle on a 3D interpretation because it's the very same time steps that you're using for posting videos you're using for settling with a static image and what I found fascinating about and maybe this is something that that is already in the literature but this idea of going up and down in the layers as you move through time --it's that's always been in recurrent
Nets. So to begin with recurrentness we just have one hidden layer so typical lstms and so on would have one hidden layer and then Alex Graves the idea of having multiple hidden layers and showed that it was a winner
so that idea has been around but it's always been paired with back propagation as the learning algorithm and in that case it was back propagation through time which was completely unrealistic.


21.48: **Brain is not static so you're not perceiving in a truly static fashion how much of this grew out of Simclr's contrastive learning or end grads activity differences**

A couple of years ago I got very excited because I was trying to make a more biologically plausible version of things like Simclr. There's a whole bunch of things like Simclr, it wasn't the first of them in fact it's something a bit like simpler that Sue Becker and I published in about 1992 in nature but we didn't use negative examples we tried to analytically compute the negative phase and there was a mistake, it just that would never work. Once you start using negative examples then you get things like Simclr and I discovered that you could separate the phases that they didn't and that got me very excited a few years ago because
it seemed like I only had an explanation for what sleep was for. One big difference is Simclr is taking two different Patches from the same image and if they're from the same image it's trying to make them have a similar representation, if they're from different images it's trying to make them have different representations. Once they're different it doesn't try and make them more different and when you think how to say this simply involves looking at two representations and seeing how similar they are and that's one way to measure agreement and in fact **if you think about the squared difference between two vectors that decomposes into three terms the sum is to do with the square of the first vector there's something to do with the square of the second vector and then there's the scalar product of the two vectors and the scalar product of the two vectors is the only kind is the only interactive term and so it turns out that squared difference is very like a scalar product -- a big Square difference is like a small scale of product.** Now there's a different way to measure agreement which is to take the things you'd like to agree and feed them into one set of neurons and now if two sources coming into that set of neurons agree you'll get high activity in those neurons it's like positive interference between light waves and if they disagree you'll get low activity and if you measure agreement just by the activity in a layer of neurons you're measuring an agreement between the inputs then you don't have to have two things you can have as many things as you like you don't have to divide the input into two patches and say to the representation of the two patches agree you can just say I've got a hidden layer, does this hidden layer get highly active and it seems to me that's a better way to measure agreement it's easier for the brain to do and it's particularly interesting if you
have spiking neurons because what **I'm using at present doesn't use Spike inputs it just says a hidden layer is really asking are my inputs agreeing with each other in which case I'll be highly active or
are they disagree in which case I won't but if the inputs arrive at specific times very precise times like spikes do then you can ask not just the same neurons being stimulated but are they being stimulated at exactly the same time and that's a much sharper way to measure agreement so spiking neurons seem particularly good for measuring agreement** which is what I need that's the objective function to get agreement in the positive phase is not in the negative phase and I'm thinking about ways of trying to
implement spiking neurons to make this work better but that's one big difference from Simclr that you're not taking two things and saying do they agree you're just taking all the inputs coming into a layer and saying do all those inputs agree. 

(When you talk about the activity that's similar to what you were doing with **end grads** where you're comparing top-down predictions and bottom-up predictions.)

When you do the recurrent version of the forward algorithm, at each time step neurons in a layer getting top down input and bottom-up input and they'd like them to agree and if your objective function is to have high activity they'd like to make things highly active. There's another version of the forward algorithm where the objective is to have low activity and then you want the top down to cancel out the bottom up and then it looks much more like predictive coding it's not quite the same but it's very similar. But let's stick with the version where you're going for high activity you want the top down and bottom up to agree and give you
high activity but notice that it's not like the top down is a derivative so in an attempt to implement backprob in neural Nets and have top down things which are like derivatives and bottom-up things which are like activities and you try and use temporal differences to give you the derivatives and that's somewhat different here everything's activities you're never propagated derivatives.

21.48: **This algorithm also does away with the idea of dynamic routing that you talked about with stacked capsule encoders**

Yes. so with capsules I moved on from the dynamic routing to having what are called Universal capsules. Capsule would be a small collection of neurons and in the original capsules models that collection of neurons would only be able to represent one type of thing like a nose and a different kind of capsule
would represent a mouse in Universal capsules what you'd have is that each capsule could represent any type of thing so it would have different activity patterns to represent the different kinds of things that might be there. The capsule would be dedicated to a location in the image so a capsule will be representing what kind of thing you have at that location at a particular level of butthole hierarchy so it might be representing you that at the part level you have a nose nd then at a higher level you'd have other capsules that are representing other at the object level you have a face or something but when you get rid of the dedication of a bunch of neurons to a particular type of thing you don't need to do routing anymore. And in the forward forward algorithm I'm not doing routine and one of the diagrams in the paper from the product is actually taken from my paper on pothole hierarchies my last paper on capsule models. So I had a system called glom an imaginary system and the problem with it was I never had a plausible learning out of it and the ff algorithm is a plausible learning algorithm for glom is something that's neurally reasonable.
(What was fascinating to me at least about capsules is that they captured the 3D nature of reality) Lots of neural Nets are now doing that so Nerf models neural Regions Field models, now giving you very good 3D models in neural Nets so you can see something from a few different viewpoints and then produce an image of what it would look like from a new viewpoint that's very good for example making smooth videos from frames that are taken a quite long time intervals. but in the forward forward algorithm what's your intuition that this is the if indeed everything works out that this is a model for information processing in the cerebral cortex and that perception of depth and the 3D nature of reality would emerge in particular if I'm showing you a video and the Viewpoint is changing during the video then what you'd want is that the hidden layers should represent 3D structure. That's all pie in the sky at present go ahead reach that stage but yeah but with capsules because I think you you
referred to pixels having depth
so that if one object moved in front of
another the system understood that the
that it was behind
the thing in front of it
do you capture that with forward
you would want it to learn to deal with
that yes yeah I wouldn't wire that in
but it's an obvious feature video that
it should learn about with babies
they learn in just a few days to get
structure from motion that is if I take
a static scene
and I move the Observer
or if I take keep the Observer
stationary
and the experiments were done with a
piece of paper folded into a w
and if you see it the wrong way around
it looks weird
and so
experiments done by Elizabeth Stokey and
other people use the idea that
you can tell a lot about the perception
of a baby by seeing what they're
interested in because they're interested
in things that look odd and so they'll
pay more attention to things that look
hard and within a few days
they learn to deal with how 3D structure
ought to be related to motion and if you
make it related wrong they think it's
weird
so they learn that very fast whereas it
takes them like at least six months I
think to learn to do stereo
to get it from the true eyes it's just
much easier to get from video than from
stereo but from evolutionary point of
view if something's really easy to learn
there's not much Point wiring it in
you've been working in Matlab famously
now
on toy problems are you starting to
scale are you still refining
I'm doing a bit of scanning I'm using a
GPU to make these go a bit faster but
I'm still at the stage where there's
very basic properties of the algorithm
I'm exploring in particular how to
generate negative data effectively from
the model
and until I've got the sort of basic
stuff working nicely
I think it's silly to scale it up as
soon as you scale it up it's slower to
investigate changes in the basic
algorithm and I'm still at the stage
where there's lots and lots of different
things I want to investigate for example
here's just one little thing that I
haven't had time to invest in yet you
can use
as your objective function to have high
activity
in the positive phase and low activity
in the negative phase
and if you do that it'll find nice
features in the hidden units
or you can have a zero objective
function to have low activity in the
positive phase
if you do that it'll find nice
constraints
if you think about what physicists do
they try and understand nature
by finding apparently different things
that add up to zero
another way of saying is that they're
equal and opposite but
if you take force and you subtract mass
times acceleration you get zero
but that's a constraint
okay
so if you have two sorts of information
one of which is force and the other
which is mass times acceleration
you'd like to
have hidden units that see both those
inputs and that say zero
no activity
and then when they see things that don't
fit the physics
they'll have high activity they'll be
the negative data
so that's called a constraint
and so if you make your objective
function B have low activity for real
things and high activity for
things that aren't real you'll find
constraints in the data as opposed to
features
so features are things that have high
variance and constraints of things that
have low variance
a feature something that's got higher
variance and it should have constrained
as low various than it should now
there's no reason why you shouldn't
have two types of neurons one's looking
for features and one's looking for
constraints
and we know with just linear models
that
a method like principal components
analysis
looks for the directions in the space at
the highest variance they're like
features







